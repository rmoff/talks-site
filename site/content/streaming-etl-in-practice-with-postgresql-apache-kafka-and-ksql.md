---
title: "Streaming ETL in Practice with PostgreSQL, Apache Kafka, and KSQL"
slug: "streaming-etl-in-practice-with-postgresql-apache-kafka-and-ksql-sd"
date: "2018-07-03T08:00:00"
event: ""
location: ""
image: "/images/streaming-etl-in-practice-with-postgresql-apache-kafka-and-ksql/slide_000.jpg"
pdf: "/pdfs/streaming-etl-in-practice-with-postgresql-apache-kafka-and-ksql.pdf"
source: "speakerdeck"
speakerdeck_slug: "streaming-etl-in-practice-with-postgresql-apache-kafka-and-ksql"
---

Have you ever thought that you needed to be a programmer to do stream processing and build streaming data pipelines? Think again!

Organizations recognize Apache Kafka's value as a low-latency, scalable, fault-tolerant data backbone. Developers can integrate multiple sources and systems to enable real-time analytics and event-driven architectures using configuration rather than custom code.

The talk covers streaming data from PostgreSQL into Kafka using Change Data Capture (CDC) and Kafka Connect, then using KSQL to filter, aggregate, and join data before routing it to multiple targets like Elasticsearch and S3. All of this can be accomplished without a single line of code!
